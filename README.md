---
component-id: tonalities-knowledge-graph
name: Tonalities Knowledge Graph
description: The Knowledge Graph about collaborative annotation of MEI scores with historical analytical concepts
type: Repository
release-date: 12/01/2022
release-number: v0.1
work-package: 
- WP1
licence: CC BY
links:
- https://github.com/polifonia-project/tonalities-knowledge-graph
credits:
- https://github.com/guillotel-nothmann
- https://github.com/margur78
- https://github.com/Adam-Filaber
- https://github.com/felix-commits
- https://github.com/AntoineLbrn
- https://github.com/Amleth
---

# tonalities-knowledge-graph

Tonalities Knowledge Graph stores all the data consumed and produced by the Tonalities application (https://github.com/sherlock-iremus/sherlock-tonalities).

Tonalities consumes three kinds of semantic data:

1. MEI scores are fully converted to RDF triples: each XML element receives a unique IRI, each XML attribute gives birth to a RDF triple, and basic CIDOC-CRM patterns are used to express the type (note, rest, verseâ€¦), the id (reflected in the IRI of the corresponding semantic data) and the nesting of each element. However, some analytical tasks assume the ability to address observables that are not represented by musical signs, such as a) verticalities (score offsets), b) note offsets and c) arbitrary selections of MEI elements. Score and note offsets are extracted with music21 libraries, and free selections are modeled as basic CIDOC-CRM patterns. Each of these "beyond-MEI" observables also receives an unique IRI. 
2. The project formalizes theoretical knowledge (either historical sources or today's theory) in the form of [OWL ontologies](https://github.com/polifonia-project/modal-tonal-ontology/). These ontologies provide concepts and properties which, imported into the Tonalities Knowledge Graph and in Tonalities application, provide an analytical vocabulary to annotate scores.
3. Tonalites allows to display and compare two kinds of semantic annotations that "connect" analytical observables and aforementioned theoretical concepts: those created manually in the interface and those generated by programs relying on machine learning and algorithms using formalized knowledge production rules. Each annotation is expressed as a CIDOC-CRM event, and is thus signed (by a human musicologist or by a specific algorithm) and dated, and takes the form of a reification of a RDF triple. An annotation may be simple, in which case the object/body is a single value (like a dissonance type associated with a subject/target representing a note). Annotations may also be complex structures (with types and properties), for example when an analyst describes the inner structure of a cadence. In such cases, a macro selection may be annotated with cadence types ("DiminishedCadence", "PerfectCadence", etc.), and may contain sub-selections annotated with a "role" within the cadence through properties ("hasAltizan", "hasCantizan",  etc).  Within each of these sub-selections, each note may be annotated in turn with properties ("hasAntepenultima", "hasFinalis", etc.).

Through user interaction, Tonalities produces two kinds of semantic data:
1) Arbitrary selections of MEI elements and "beyond-MEI" elements (such as verticalities) (see 1. above).
2) Signed annotations connecting a Selection and a concept or an analytical construct (see 3. above).

Tonalities directly writes in the RDF triple store through an [ORCID-authenticated REST API](https://github.com/sherlock-iremus/sherlock-service).

Moreover, a "catalogue" of available MEI scores with top-level metadata (works, composers, genre...) is curated in a [CMS](https://directus.io/) which provides musicologists with an intuitive GUI. Relational data are converted to semantic data (modeled as CIDOC-CRM/LRMoo/DOREMUS entities) with a [Python script](https://github.com/sherlock-iremus/sherlock-data-v2/blob/main/rdfizers/modality-tonality/catalogue/catalogue-directus2rdf.py). 
These RDF data represent a fourth type of semantic data which are not directly used in the annotation tool but are part of the knowledge graph.

Tonalities Knowledge Graph is available via the IREMUS SPARQL endpoint `https://data-iremus.huma-num.fr/sparql` ([Yasgui](https://yasgui.triply.cc/#query=SELECT%20*%0AWHERE%20%7B%0A%20%20GRAPH%20%3Fg%20%7B%0A%20%20%20%20%3Fs%20%3Fp%20%3Fo%20.%0A%20%20%7D%0A%7D%0ALIMIT%2011&endpoint=https%3A%2F%2Fdata-iremus.huma-num.fr%2Fsparql&requestMethod=POST&tabTitle=Query&headers=%7B%7D&contentTypeConstruct=application%2Fn-triples%2C*%2F*%3Bq%3D0.9&contentTypeSelect=application%2Fsparql-results%2Bjson%2C*%2F*%3Bq%3D0.9&outputFormat=table)).

See some Tonalities statistical data on Melody: https://projects.dharc.unibo.it/melody/tonalities/tonalities.

Shield: [![CC BY-NC-SA 4.0][cc-by-nc-sa-shield]][cc-by-nc-sa]

This work is licensed under a
[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License][cc-by-nc-sa].

[![CC BY-NC-SA 4.0][cc-by-nc-sa-image]][cc-by-nc-sa]

[cc-by-nc-sa]: http://creativecommons.org/licenses/by-nc-sa/4.0/
[cc-by-nc-sa-image]: https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png
[cc-by-nc-sa-shield]: https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg